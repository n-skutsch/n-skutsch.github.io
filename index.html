<!doctype html><html class="no-js"><head><meta charset="utf-8"><title>My Projects</title><meta name="description" content=""><meta name="viewport" content="width=device-width">

<link href="http://fonts.googleapis.com/css?family=Raleway:300,400,600" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="style.css">
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<body>

<div class="container">

    <section class="header" id="intro">

        <h2 class="title">My Projects</h2>

        <h6>by Nicolai Skutsch (<a href="mailto:nicolai.skutsch@htw-berlin.de">nicolai.skutsch@htw-berlin.de</a>)</h6>

        <div class="row">
            <p>On this page, you can find a short description of the projects I have worked on during my master studies. If you are interested in one of these topics or if you have any questions, feel free to contact me!</p>
        </div>

    </section>


    <div class="docs-section" id="image-harmonization">

        <h3 class="section-heading">Image Harmonization using Single Image GANs</h3>

        <div class="row">
            <img class="u-max-full-width" src="image-harmonization/images/banner.jpg">
        </div>

        <p></p>

        <p>The main goal of this project was to translate an existing image harmonization network written in Pytorch to Tensorflow. The existing network was a Single Image GAN (SinGAN), which takes only a single image as an input. It was first trained to recreate the original input image from augmented versions of that image, and then used after training to harmonize masked regions of the input with the rest of the image texture. The main challenge was to implement the functionality that was already available in pytorch but were still missing in Tensorflow.</p>

        <p>A full report on this project can be found <a href="image-harmonization/index.html">here</a>.</p>

    </div>

    <div class="docs-section" id="hyperlapse-video-stabilization">

        <h3 class="section-heading">Video Stabilization of Hyperlapse Videos</h3>

        <div class="row">
            <img class="u-max-full-width" src="hyperlapse-video-stabilization/images/banner.jpg">
        </div>

        <p></p>

        <p>The main goal of this project was to extend an existing full-frame video stabilization network to improve the performance on hyperlapse videos. The existing network consists of two different networks: a U-Net, which is responsible for computing a stabilized middle-frame between two frames, and a ResNet, which is responsible for texture refinement. The original network was first trained to generate a new middle frame from the two adjacent frames and a spatially translated pseudo ground truth frame, and then used after training to compute a set of frames with less spatial jitter than the original video. This could be done iteratively several times. Since most of the original frames are not used when the network is applied to a hyperlapse video, I extended the network to use all the frames of the original video to improve the stabilization performance.</p>

        <p>A full report on this project can be found <a href="hyperlapse-video-stabilization/index.html">here</a>.</p>

    </div>

    <div class="docs-section" id="aneurysms">

        <h3 class="section-heading">Aneurysm Detection and Segmentation</h3>

        <div class="row">
            <img class="u-max-full-width" src="aneurysms/images/banner.jpg">
        </div>

        <p></p>

        <p>The main goal of this project was to detect and segment aneurysms in 3D medical images and to estimate the risk of a rupture. It was based on the <a href="https://cada.grand-challenge.org/">CADA - Cerebral Aneurysm Detection Challenge</a>. For this purpose, we as a group designed a U-Net and experimented with different pre-processing methods, post-processing methods, and model parameters. With our final model, we achieved an F2-score of 0.87.</p>

    </div>

</div>
