<!doctype html><html class="no-js"><head><meta charset="utf-8"><title>My Projects</title><meta name="description" content=""><meta name="viewport" content="width=device-width">

<link href="http://fonts.googleapis.com/css?family=Raleway:300,400,600" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="style.css">
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<body>

<div class="container">

    <section class="header" id="intro">

        <h2 class="title">My Projects</h2>

        <h6>by Nicolai Skutsch (<a href="mailto:n.skutsch@tu-berlin.de">n.skutsch@tu-berlin.de</a>)</h6>

        <div class="row">
            <p>On this site, you can find a short description of the projects I worked on during my Masters Degree. If you are interested in one of these topics or have any questions, feel free to contact me!</p>
        </div>

    </section>


    <div class="docs-section" id="image-harmonization">

        <h3 class="section-heading">Image Harmonization using Single Image GANs</h3>

        <div class="row">
            <img class="u-max-full-width" src="image-harmonization/images/banner.jpg">
        </div>

        <p></p>

        <p>In this project, the main goal was to translate an existing network for image harmonization written in pytorch to Tensorflow. The existing network was a Single Image GAN (SinGAN) which takes only a single image as an input. It was first trained to recreate the original input image from augmented versions of this image and then used after training to harmonize masked regions of the input with the rest of the image texture. The main challenge was to implement the functionalities which are already given in pytorch but were still missing in Tensorflow.</p>

        <p>A full report on this project can be found <a href="image-harmonization/index.html">here</a>.</p>

    </div>

    <div class="docs-section" id="hyperlapse-video-stabilization">

        <h3 class="section-heading">Video Stabilization of Hyperlapse Videos</h3>

        <div class="row">
            <img class="u-max-full-width" src="hyperlapse-video-stabilization/images/banner.jpg">
        </div>

        <p></p>

        <p>In this project, the main goal was to extend an existing network for full-frame video stabilization to improve the performance on hyperlapse videos. The existing network consisted of two different networks: a U-Net which was responsible for calculating a stabilized middle-frame between two frames and a ResNet which was responsible for texture refinements. The network was first trained to generate a new middle frame from the two neighboring frames and a spatially translated pseudo ground truth frame and then used after training to calculate a set of frames with less spatial jitter than the original video. This could be done multiple times iteratively. Since most of the original frames won't be used if the network is applied to a hyperlapse video, I extended the network to use all the frames of the original video and therefore improve the stabilization performance.</p>

        <p>A full report on this project can be found <a href="hyperlapse-video-stabilization/index.html">here</a>.</p>

    </div>

    <div class="docs-section" id="aneurysms">

        <h3 class="section-heading">Aneurysm Detection and Segmentation</h3>

        <div class="row">
            <img class="u-max-full-width" src="aneurysms/images/banner.jpg">
        </div>

        <p></p>

        <p>In this project, the main goal was to detect and segment aneurysms in 3D medical images and estimate the risk of a rupture. It was based on the <a href="https://cada.grand-challenge.org/">CADA - Cerebral Aneurysm Detection Challenge</a>. For this purpose, we as a group designed a U-Net and experimented with different pre-processing methods, post-processing methods and model parameters. With the final model, we achieved an F2-score of 0.87.</p>

    </div>

</div>
